% --- Template for thesis / report with tktltiki2 class ---
%
% last updated 2013/02/15 for tkltiki2 v1.02

\documentclass[11pt,finnish]{tktltiki2}

% tktltiki2 automatically loads babel, so you can simply
% give the language parameter (e.g. finnish, swedish, english, british) as
% a parameter for the class: \documentclass[finnish]{tktltiki2}.
% The information on title and abstract is generated automatically depending on
% the language, see below if you need to change any of these manually.
%
% Class options:
% - grading                 -- Print labels for grading information on the front page.
% - disablelastpagecounter  -- Disables the automatic generation of page number information
%                              in the abstract. See also \numberofpagesinformation{} command below.
%
% The class also respects the following options of article class:
%   10pt, 11pt, 12pt, final, draft, oneside, twoside,
%   openright, openany, onecolumn, twocolumn, leqno, fleqn
%
% The default font size is 11pt. The paper size used is A4, other sizes are not supported.
%
% rubber: module pdftex

% --- General packages ---

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsfonts,amsmath,amssymb,amsthm,booktabs,color,enumitem,graphicx}
\usepackage[pdftex,hidelinks]{hyperref}

\usepackage{setspace}
\onehalfspacing

% Automatically set the PDF metadata fields
\makeatletter
\AtBeginDocument{\hypersetup{pdftitle = {\@title}, pdfauthor = {\@author}}}
\makeatother

% --- Language-related settings ---
%
% these should be modified according to your language

% babelbib for non-english bibliography using bibtex
\usepackage[fixlanguage]{babelbib}
\selectbiblanguage{finnish}

% add bibliography to the table of contents
\usepackage[nottoc]{tocbibind}
% tocbibind renames the bibliography, use the following to change it back
\settocbibname{Lähteet}

% --- Theorem environment definitions ---

\newtheorem{lau}{Lause}
\newtheorem{lem}[lau]{Lemma}
\newtheorem{kor}[lau]{Korollaari}

\theoremstyle{definition}
\newtheorem{maar}[lau]{Määritelmä}
\newtheorem{ong}{Ongelma}
\newtheorem{alg}[lau]{Algoritmi}
\newtheorem{esim}[lau]{Esimerkki}

\theoremstyle{remark}
\newtheorem*{huom}{Huomautus}


% --- tktltiki2 options ---
%
% The following commands define the information used to generate title and
% abstract pages. The following entries should be always specified:

\title{Normalisoitu pakkausetäisyys}
\author{Timo Sand}
\date{\today}
\level{Kandidaatintutkielma}
\abstract{Aine}

% The following can be used to specify keywords and classification of the paper:

\keywords{avainsana 1, avainsana 2, avainsana 3}

% classification according to ACM Computing Classification System (http://www.acm.org/about/class/)
% This is probably mostly relevant for computer scientists
% uncomment the following; contents of \classification will be printed under the abstract with a title
% "ACM Computing Classification System (CCS):"
% \classification{}

% If the automatic page number counting is not working as desired in your case,
% uncomment the following to manually set the number of pages displayed in the abstract page:
%
% \numberofpagesinformation{16 sivua + 10 sivua liitteissä}
%
% If you are not a computer scientist, you will want to uncomment the following by hand and specify
% your department, faculty and subject by hand:
%
% \faculty{Matemaattis-luonnontieteellinen}
% \department{Tietojenkäsittelytieteen laitos}
% \subject{Tietojenkäsittelytiede}
%
% If you are not from the University of Helsinki, then you will most likely want to set these also:
%
% \university{Helsingin Yliopisto}
% \universitylong{HELSINGIN YLIOPISTO --- HELSINGFORS UNIVERSITET --- UNIVERSITY OF HELSINKI} % displayed on the top of the abstract page
% \city{Helsinki}
%

\newcommand{\engl}[1]{\emph{(engl. #1)}}


\begin{document}

% --- Front matter ---

\frontmatter      % roman page numbering for front matter

\maketitle        % title page
% \makeabstract     % abstract page

\tableofcontents  % table of contents

% --- Main matter ---

\mainmatter       % clear page, start arabic page numbering

\section{Johdanto} % (fold)
\label{sec:johdanto}
\iffalse
  TODO: All data are created equal but some data are more alike than others. We propose a method expressing this alikeness, using a new similarity metric based on compression. It is parameter-free in that it does not use any features or background knowledge about the data, and can without changes be applied to different areas and across area boundaries. It is universal in that it approximates the parameter expressing similarity of the dominant feature in all pairwise comparisons. It is robust in the sense that its success appears independent from the type of compressor used.

  Non-Feature Similarities: Our aim is to capture, in a single simi- larity metric, every effective distance: effective versions of Hamming distance, Euclidean distance, edit distances, alignment distance, Lempel–Ziv distance [11], and so on. This metric should be so general that it works in every domain: music, text, literature, programs, genomes, executables, natural language determination, equally and si- multaneously. It would be able to simultaneously detect all similarities betweenpiecesthatothereffectivedistancescandetectseperately.

  To apply this ideal precise mathematical theory in real life, we have to replace the use of the non computable Kolmogorov complexity by an approximation using a standard real-world compressor. Earlier approaches resulted in the first completely automatic construction of the phylogeny tree based on whole mitochondrial genomes, [29]–[31], a completely automatic construction of a language tree for over 50 Euro-Asian languages [31], detects plagiarism in student programming assignments[8],givesphylogenyofchainletters[5],andclusters music [10]. Moreover, the method turns out to be robust under change of the underlying compressor-types: statistical (\emph{PPMZ}), Lempel–Ziv based dictionary (\emph{gzip}), block based (\emph{bzip2}), or special purpose (\emph{Gencompress}).
\fi
\paragraph{} % (fold)
\label{par:intro-1}
  Kaikki data on luotu samanveroiseksi, mutta jotkut ovat samankaltaisempia kuin toiset.
  Esitämme tavan jolla esittää tämä samankaltaisuus, käyttäen uutta samankaltaisuuden metriikkaa \engl{similarity metric} joka perustuu tiedoston pakkaamiseen. Metriikka on parametriton, se ei käytä datan ominaisuuksia tai taustatietoa siitä, ja sitä voi soveltaa eri aloihin ilman muunnoksia.
  Metriikka on universaali siten, että se approksimoi parametrin, joka kaikissa pareittain vertailuissa ilmaisee samankaltaisuutta hallitsevassa piirteessä. Se on vakaa siinä mielessä, että sen tulokset ovat riippumattomia käytetystä pakkaajasta \cite{CV05}. Pakkaajalla tarkoitetaan pakkausohjelmaa kuten \emph{gzip, ppmz, bzip2}.

% paragraph  (end)

\paragraph{} % (fold)
\label{par:intro-2}
   \textbf{Pakkaukseen perustuva samankaltaisuus} \engl{Compression-Based Similarity}: Tällaisen `universaalin' metriikan kehittivät Cilibrasi ja Vitanyi \cite{CV05}. Yksinkertaistettuna kaksi objektia ovat lähellä toisiaan jos voimme `pakata' yhden objektin huomattavasti tiiviimmin toisen objektin datalla. ABstraktina ideana toimii se, että voimme kuvailla ytimekkäämmin yhden palan toisen avulla, jos palat ovat samankaltaisia. Tämän esittelemme luvussa \ref{sec:normalisoitu_pakkauset_isyys} ja esittelemme mihin teoriaan algoritmi perustuu ja miten se toimii. Edellä mainitun vakauden esittämiseen käytämme useaa tosielämän pakkausalgoritmiä: tilastollista (PPMZ), Lempel-Ziv -algoritmiin pohjautuvaa hakemistoa (gzip), lohkoperusteista (bzip2) tai erityistä tarkoitusta varten (Gencompress).

   Kun määrittelemme ryhmän sallittavia etäisyyksia \engl{admissible distances} haluamme sulkea pois epärealistiset, kuten $f(x,y) = \frac{1}{2}$ jokaiselle parille $x \neq y$. Saavutamme tämän rajoittamalla objektien lukumäärän annetussa etäisyydessä objektiin. Teemme tämän huomioimalla vain todellisia etäisyyksia seuraavasti: Määräämme sopivan ja tietyn ohjelmointikielen, joka toimii tutkielman ajan referenssikielenä.

% paragraph  (end)

\paragraph{} % (fold)
\label{par:intro-3}
  Luvussa \ref{sec:k_ytt_kohteet} esittelemme algoritmin käyttökohteita monelta eri alueelta. Aloitamme sillä, miten yleiseti NCD:n avulla pystymme klusteroimaan tuloksia eri kategorioihin; miten musiikkikappaleet klusteroituu saman artistin alle, miten kuvantunnistuksessa saamme ryhmitettyä samankaltaiset kuvat ja miten sienten genomista saamme tarkan lajiryhmityksen.

  Syvennymme musiikin, kuvantunnistuken ja dokumenttien kategorisoinnin tuloksiin lopussa lukua.

% paragraph  (end)

\paragraph{} % (fold)
\label{par:intro-4}
  Luvussa \ref{sec:algoritmin_ongelmat_ja_ominaisuudet} esitellään NCD:n kestävyyttä ja ongelmia. Ensiksi esitellään miten kohina vaikuttaa NCD:n tuloksiin, lisäämällä kohinaa vähitellen toiseen tiedostoista jota pakataan ja mittaamalla samankaltaisuutta tämän jälkeen. Saamme nähdä miten paljon kohina vaikuttaa NCD:n laskemiin etäisyyksiin ja että huonontaako se klusteroinnin tuloksia.

  Mikään algoritmi ei ole täydellinen ja niin tälläkin on ongelmansa. Algoritmissä itsessään ei ole selvää heikkoutta, mutta sen käytössä on otettava pakkaajan valinta huomioon, koska sonet suosituista pakkausalgoritmeistä ovat optimoituja tietyn kokoisille tiedostoille. Niissä on niinkutsuttu ikkunakoko \engl{window size} joka määrittelee mikä tiedostokoko on sopiva. Jos tiedostokoko on pienempi kuin ikkunakoko, niin pakkaus on tehokasta, kun mennään sen yli niin pakkauksesta tulee huomattavasti tehottomampaa. Esittelemme tuloksia eri pakkausalgoritmejen vertailuista ja mikä näistä algoritmeistä on parhaimmaksi havaittu NCD:n kanssa käytettäväksi.

% paragraph  (end)

\paragraph{} % (fold)
\label{par:intro-5}
  NCD ei ole ainut metriikka jolla voidaan mitata samankaltaisuutta. Internettiä hyödyntäen on tehty metriikka joka käyttää hakukoneita samankaltaisuuden tutkimiseen, tämä on nimetty Google samankaltaisuusetäisyydeksi \engl{Google Similarity Distance}; se toimii myös muilla hakukoneilla kuin Googlella. Luvussa \ref{sec:muita_samankaltaisuuden_metriikoita} esitellemme tämän sekä muita samankaltaisuuden metriikoita.

% paragraph  (end)

% section johdanto (end)

\section{Normalisoitu Pakkausetäisyys: Mistä se koostuu, miten se toimii?} % (fold)
\label{sec:normalisoitu_pakkauset_isyys}
  \subsection{Kolmogorov kompleksisuus} % (fold)
\label{sub:kolmogorov_kompleksisuus}

  % Esitellään K(x) ensin
  Lyhimmän binääriohjelman pituus, joka palauttaa $x$ syötteellä $y$, on \emph{Kolmogorov kompleksisuus} $x$:stä syötteellä $y$; tämä merkitään $K(x|y)$. Pohjimmillaan Kolmogorov kompleksisuus tiedostosta on sen äärimmäisesti pakatun version pituus.

% subsection kolmogorov_kompleksisuus (end)
\subsection{Normalisoitu Informaatioetäisyys} % (fold)
\label{sub:normalisoitu_informaatioet_isyys}

  Artikkelissa \cite{CV05} on esitelty \emph{informaatioetäisyys} $E(x,y)$, joka on määritelty lyhimpänä binääriohjelmana, joka syötteellä $x$ laskee $y$:n ja syötteellä $y$ laskee $x$:n. Tämä lasketaan seuraavasti \cite{10.1109/WDM.2004.1358107}

  \begin{align}
    E(x,y) &= max\{K(x|y),K(y|x)\}.
  \end{align}

  Normalisoitu versio informaatioetäisyydestä ($E(x,y)$), jota kutsutaan \emph{normalisoiduksi informaatioetäisyydeksi}, on määritelty seuraavasti

  \begin{align}
    NID(x,y) &= \frac{ max\{K{(x|y)},K{(y|x)}\} }{ max \{K(x),K(y)\}}.
  \end{align}

  % NID on paras mahdollinen etäisyyden metriikka
  Tätä kutsutaan \emph{samankaltaisuuden metriikaksi}, koska tämän on osoitettu \cite{CV05} täyttävän vaatimukset etäisyyden metriikaksi. \emph{NID} ei kuitenkaan ole laskettavissa tai edes semi-laskettavissa, koska Turingin määritelmän mukaan Kolmogorov kompleksisuus ei ole laskettavissa.
  Nimittäjän approksimointi annetulla kompressorilla $C$ on $max \{C(x),C(y)\}$. Osoittajan paras approksimaatio on $max\{C(xy),C(yx)\} - \min\{C(x),C(y)\}$ \cite{CV05}.
  Kun \emph{NID} approksimoidaan oikealla kompressorilla, saadaa tulos jota kutsutaan \emph{normalisoiduksi pakkausetäisyydeksi}. Tämä esitellään formaalisti myöhemmin.
% subsection normalisoitu_informaatioet_isyys (end)

\subsection{Normaali Kompressori} % (fold)
\label{sub:normaali_kompressori}

  Seuraavaksi esitämme aksioomia, jotka määrittelevät laajan joukon kompressoreita ja samalla varmistavat \emph{normalisoidussa pakkausetäisyydessä} halutut ominaisuudet. Näihin kompressoreihin kuuluvat monet tosielämän kompressorit.

  Kompressori $C$ on \emph{normaali} jos se täyttää seuraavat aksioomat, $O(log n)$ termiin saakka:

  \begin{enumerate}
    \item \emph{Idempotenssi}: $C(xx) == C(x)$ ja $C(\lambda) = 0$, jossa $\lambda$ on tyhjä merkkijono,
    \item \emph{Monotonisuus}: $C(xy) \geq C(x)$,
    \item \emph{Symmetrisuus}: $C(xy) == C(yx)$ ja
    \item \emph{Distributiivisuus}: $C(xy) + C(z) \leq C(xz) + C(yz)$.
  \end{enumerate}
% subsection normaali_kompressori (end)

\subsection{Normalisoitu Pakkausetäisyys} % (fold)
\label{sub:normalisoitu_pakkauset_isyys}

  Normalisoitua versiota \emph{hyväksyttävästä etäisyydestä} $E_c(x,y)$, joka on kompressoriin $C$ pohjautuva approksimaatio \emph{normalisoidusta informaatioetäisyydestä}, kutsutaan nimellä \emph{Normalisoitu Pakkausetäisyys (NCD)} \cite{CV05}. Tämä lasketaan seuraavasti

  \begin{align}
    NCD(x,y) &= \frac{C(xy)-min\{C(x),C(y)\}}{max\{C(x),C(y)\}}.
  \end{align}

  \emph{NCD} on funktioden joukko, joka ottaa argumenteiksi kaksi objektia (esim. tiedostoja tai Googlen hakusanoja) ja tiivistää nämä, erillisinä ja yhdistettyinä. Tämä funktioden joukko on parametrisoitu käytetyn kompressorin $C$ mukaan.

  Käytännössä \emph{NCD}:n tulos on välillä $0 \leq r \leq 1+ \epsilon$, joka vastaa kahden tiedoston eroa toisistaan; mitä pienempi luku, sitä enemmän tiedostot ovat samankaltaisia. Tosielämässä pakkausalgoritmit eivät ole yhtä tehokkaita kuin teoreettiset mallit, joten virhemarginaali $\epsilon$ on lisätty ylärajaan. Suurimmalle osalle näistä algoritmeistä on epätodennäköistä että  $\epsilon > 0.1$.
% subsection normalisoitu_pakkauset_isyys (end)

  Luonnollinen tulkinta \emph{NCD}:stä, jos oletetaan $C(y) \geq C(x)$, on

  \begin{align}
    NCD(x,y) = \frac{C(xy)-C(x)}{C(y)}.
 \end{align}

  Eli etäisyys $x$:n ja $y$:n välillä on suhde $y$:n parannuksesta kun $y$ pakataan käyttäen $x$:ää, ja $y$:n pakkauksesta yksinään; suhde ilmaistaan etäisyytenä bittien lukumääränä kummankin pakatun version välillä.

  Kun kompressori on normaali niin \emph{NCD} on normalisoitu hyväksyttävä etäisyys, joka täyttää metriikan yhtälöt, eli se on samankaltaisuuden metriikka.


  % O(log n) alkuun "hinta siitä että siirrytänä Kolmogorov-kompleksisuudesta laskettavaan"
% section normalisoitu_pakkauset_isyys (end)

\section{Käyttökohteet} % (fold)
\label{sec:k_ytt_kohteet}
  \subsection{Klusterointi} % (fold)
  \label{sub:klusterointi}
    \subsubsection{Tuloksia} % (fold)
    \label{ssub:tuloksia}

    % subsubsection tuloksia (end)
  % subsection klusterointi (end)
  \subsection{Kuvantunnnistus} % (fold)
  \label{sub:kuvantunnnistus}

  % subsection kuvantunnnistus (end)
% section k_ytt_kohteet (end)

\section{Algoritmin ongelmat ja ominaisuudet} % (fold)
\label{sec:algoritmin_ongelmat_ja_ominaisuudet}
  \subsection{Kohinansietokyky} % (fold)
  \label{sub:kohinansietokyky}
    Kun NCD:tä käytetään kahteen eri tiedostoon toista näistä voi pitää kohinallisena versiona ensimmäisestä. Progressivisen kohinan lisääminen tiedostoon voi tuottaa tietoa mittarista(measure) itsestään. Tämän vastaavuuden perusteella voimme tehdä teoreettisen päätelmän odotetusta kohinan lisäämisen vaikutuksesta algoritmiin, mikä selittää miksi NCD voi saada suurempia arvoja kuin $1$ joissain tapauksissa. \cite{4167725}

  % subsection kohinansietokyky (end)

  \subsection{Kompressorin valinta} % (fold)
  \label{sub:kompressorin_valinta}

    \iffalse
      This paper shows that the compressors used to compute the normalized compression distance are not idempotent in some cases, being strongly skewed with the size of the objects and window size, and therefore causing a deviation in the identity property of the distance if we don’t take care that the objects to be compressed fit the windows. The relationship underlying the precision of the distance and the size of the objects has been analyzed for several well-known compressors, and specially in depth for three cases, bzip2, gzip and PPMZ which are examples of the three main types of compressors: block-sorting, Lempel-Ziv, and statistic.
    \fi
  % subsection kompressorin_valinta (end)
% section algoritmin_ongelmat_ja_ominaisuudet (end)

\section{Muita samankaltaisuuden metriikoita} % (fold)
\label{sec:muita_samankaltaisuuden_metriikoita}
  \subsection{Google Similarity Distance} % (fold)
  \label{sub:google_similarity_distance}

  % subsection google_similarity_distance (end)
% section muita_samankaltaisuuden_metriikoita (end)
% --- References ---
%
% bibtex is used to generate the bibliography. The babplain style
% will generate numeric references (e.g. [1]) appropriate for theoretical
% computer science. If you need alphanumeric references (e.g [Tur90]), use
%
\bibliographystyle{babalpha-lf}
%
% instead.

% \bibliographystyle{babplain-lf}
\bibliography{references-fi}


% --- Appendices ---

% uncomment the following

% \newpage
% \appendix
%
% \section{Esimerkkiliite}

\end{document}
